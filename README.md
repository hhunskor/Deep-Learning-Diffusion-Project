# Deep-Learning-Diffusion-Project

**(This is a copy of my final project write-up)**

This is my final project for Middlebury's Deep Learning course. My partner, Sujay, and I chose to write a diffusion model from scratch on a small dataset of images for our project. After initially working with a dataset of high resolution landscape images that we found on Kaggle, we decided to switch to the MNIST handwritten digit dataset which contains 70,000 28x28 pixel images of handwritten numbers. Our goal was to implement a simplified UNet model that trains on noised images, along with their corresponding labels and number of noise steps, and outputs a predicted amount of noise. With this trained model, we hoped that we could feed it randomly sampled noise and then iteratively remove the noise that the model predicted to reveal a generated digit. This image generation process proved to be quite difficult and we ultimately were unable to get our code to work as intended.

There were three general steps that we took to solve this problem: build the model architecture, train it on noised images, and finally test it. The architecture that we initially implemented was a UNet inspired by an article on convolutional networks for biomedical image segmentation (see link at end of README). Unfortunately, this model had far too many parameters to run efficiently so we had to switch to a simple deep neural net. We did leave the initial UNet architecture code in our final codebase for reference though.

For our model training process, we used the Pytorch built-in MSE loss to measure the difference between the actual noise and the model’s predicted noise. We also used Adam as our optimizer and settled on a learning rate of 0.0001. We also wrote several helper functions to handle noising the images and one-hot encode the image labels and noise steps.

As previously mentioned, the model testing process was ultimately unsuccessful. This is partially due to the model’s inability to effectively learn and minimize loss. We trained the model for 100 epochs but after the first few epochs the loss remained pretty stable. The other reason for our lack of success with image generation is we were unable to iteratively denoise the randomly generated noise. We tried borrowing code from the internet, but that just further complicated things. I want to emphasize that both Sujay and I spent countless hours trying to get this part of the code to work properly and we are quite disappointed that we couldn’t get it to work. I know I plan on continuing to work on this model even after the class is over because I think we are quite close and it would be nice to get some actual output from our model.

As Sujay and I discussed in our presentation, we both learned a lot over the course of this project. I think the biggest takeaway though is the importance of keeping things simple. We came into this project thinking we could easily crank out a diffusion model that generates awesome art from scratch, and that is obviously a very computationally intense endeavor. We had to simplify our model architecture many times, simplify our dataset, and even simplify the function we were using to generate and apply noise. That said, after writing our own model, I now have a much deeper understanding of how diffusion works under the hood.

UNet architecture reference: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/
